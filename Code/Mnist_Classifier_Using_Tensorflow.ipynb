{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist Classifier Using Tensorflow.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2_9OZGscKpXy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Code is to build a classifier for MNIST dataset in Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "bKHM8ZuvKoL3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import all packages on top \n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IqvjOe3DLRae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "one is on and rest are off , used for multiclass classification for one class output will be 1, and for others it be zero"
      ]
    },
    {
      "metadata": {
        "id": "ejocvxoMLQvf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "918022c6-52b8-4a55-f6e2-27ad97cef87a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523391581365,
          "user_tz": 240,
          "elapsed": 1093,
          "user": {
            "displayName": "Kartik Joshi",
            "photoUrl": "//lh6.googleusercontent.com/-GiqP8cWbHxk/AAAAAAAAAAI/AAAAAAAAHTw/OdKomit6xfs/s50-c-k-no/photo.jpg",
            "userId": "110499684353556039611"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Read and create dataset \n",
        "\n",
        "mnist = input_data.read_data_sets('/tmp/data',one_hot=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ub05aGN2LhA0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define model variables \n",
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 500\n",
        "n_nodes_hl3 = 500\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oZRVrx1eMpwx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Place holder to store values while passing through graph \n",
        "# float value, Height of row is None and width will be 784\n",
        "x = tf.placeholder('float',[None,784])\n",
        "y = tf.placeholder('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DtOaZ3WMMxp9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Method to define model \n",
        "\n",
        "def neural_network_model(data):\n",
        "\n",
        "    # (input_data * weight)  + bias\n",
        "    hidden_1_layer = {'weights': tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
        "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "    hidden_2_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "    hidden_3_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                      'biases': tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
        "                      'biases': tf.Variable(tf.random_normal([n_classes]))}\n",
        "\n",
        "    #input_data * weight +b\n",
        "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
        "    l1 = tf.nn.relu(l1)\n",
        "\n",
        "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']),hidden_2_layer['biases'])\n",
        "    l2 = tf.nn.relu(l2)\n",
        "\n",
        "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']),hidden_3_layer['biases'])\n",
        "    l3 = tf.nn.relu(l3)\n",
        "\n",
        "    output = tf.matmul(l3,output_layer['weights'])+  output_layer['biases']\n",
        "\n",
        "    return output\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmjzGbQVM6Pv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Method to intialize model and train using mnist data and test model function \n",
        "def train_neural_network(x):\n",
        "    prediction = neural_network_model(x)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction,labels=y))\n",
        "\n",
        "    # Adam optimizer does has learning rate parameter\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "\n",
        "    #cycles for feed forward and backprop error\n",
        "    nm_epochs = 100\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        for epoch in range(nm_epochs):\n",
        "            epoch_loss = 0\n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "                epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
        "                _ ,c = sess.run([optimizer,cost], feed_dict= {x :epoch_x, y : epoch_y})\n",
        "                epoch_loss += c\n",
        "            print(\"Epoch\", epoch,' completed out of ', nm_epochs , \"Loss:\" , epoch_loss)\n",
        "        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "        accuracy =  tf.reduce_mean(tf.cast(correct,'float'))\n",
        "        print(\"Accuracuy\" ,accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L0NCTPJqNNyL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "9f8d4f9e-2c7d-41a5-fffd-c7abf51e1238",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523392783988,
          "user_tz": 240,
          "elapsed": 217545,
          "user": {
            "displayName": "Kartik Joshi",
            "photoUrl": "//lh6.googleusercontent.com/-GiqP8cWbHxk/AAAAAAAAAAI/AAAAAAAAHTw/OdKomit6xfs/s50-c-k-no/photo.jpg",
            "userId": "110499684353556039611"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Calling method \n",
        "train_neural_network(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0  completed out of  100 Loss: 2017837.1699829102\n",
            "Epoch 1  completed out of  100 Loss: 418269.66775226593\n",
            "Epoch 2  completed out of  100 Loss: 232871.4495010376\n",
            "Epoch 3  completed out of  100 Loss: 136685.82289338112\n",
            "Epoch 4  completed out of  100 Loss: 84123.85763645172\n",
            "Epoch 5  completed out of  100 Loss: 52291.381105453256\n",
            "Epoch 6  completed out of  100 Loss: 33211.36608209292\n",
            "Epoch 7  completed out of  100 Loss: 23454.480740414263\n",
            "Epoch 8  completed out of  100 Loss: 19287.406092368066\n",
            "Epoch 9  completed out of  100 Loss: 19977.134475926163\n",
            "Epoch 10  completed out of  100 Loss: 17789.355433514196\n",
            "Epoch 11  completed out of  100 Loss: 13107.530286408291\n",
            "Epoch 12  completed out of  100 Loss: 14110.305477204209\n",
            "Epoch 13  completed out of  100 Loss: 15106.359305465221\n",
            "Epoch 14  completed out of  100 Loss: 15536.232989259064\n",
            "Epoch 15  completed out of  100 Loss: 11606.355291521177\n",
            "Epoch 16  completed out of  100 Loss: 11602.830876171589\n",
            "Epoch 17  completed out of  100 Loss: 7643.6434876039575\n",
            "Epoch 18  completed out of  100 Loss: 10636.997934490442\n",
            "Epoch 19  completed out of  100 Loss: 10821.704733401537\n",
            "Epoch 20  completed out of  100 Loss: 9100.481128860076\n",
            "Epoch 21  completed out of  100 Loss: 8888.203866552562\n",
            "Epoch 22  completed out of  100 Loss: 8468.607839784087\n",
            "Epoch 23  completed out of  100 Loss: 7260.440043333256\n",
            "Epoch 24  completed out of  100 Loss: 7158.369507789612\n",
            "Epoch 25  completed out of  100 Loss: 8222.074884640431\n",
            "Epoch 26  completed out of  100 Loss: 8243.622936189175\n",
            "Epoch 27  completed out of  100 Loss: 6080.26020740675\n",
            "Epoch 28  completed out of  100 Loss: 5544.7439769133925\n",
            "Epoch 29  completed out of  100 Loss: 8278.702712931929\n",
            "Epoch 30  completed out of  100 Loss: 6887.712436703432\n",
            "Epoch 31  completed out of  100 Loss: 5808.874661455045\n",
            "Epoch 32  completed out of  100 Loss: 5803.047977298498\n",
            "Epoch 33  completed out of  100 Loss: 5499.541388705373\n",
            "Epoch 34  completed out of  100 Loss: 5998.38428690657\n",
            "Epoch 35  completed out of  100 Loss: 6006.811382889748\n",
            "Epoch 36  completed out of  100 Loss: 5486.378380402923\n",
            "Epoch 37  completed out of  100 Loss: 4440.0830036997795\n",
            "Epoch 38  completed out of  100 Loss: 4842.6927027106285\n",
            "Epoch 39  completed out of  100 Loss: 4704.365485384166\n",
            "Epoch 40  completed out of  100 Loss: 4187.005252000162\n",
            "Epoch 41  completed out of  100 Loss: 4751.221534572542\n",
            "Epoch 42  completed out of  100 Loss: 5200.929394648474\n",
            "Epoch 43  completed out of  100 Loss: 4296.466562940506\n",
            "Epoch 44  completed out of  100 Loss: 4226.557500302792\n",
            "Epoch 45  completed out of  100 Loss: 3240.6054223179817\n",
            "Epoch 46  completed out of  100 Loss: 5728.652568370104\n",
            "Epoch 47  completed out of  100 Loss: 4240.216597905295\n",
            "Epoch 48  completed out of  100 Loss: 3867.199243675772\n",
            "Epoch 49  completed out of  100 Loss: 3616.3867601156235\n",
            "Epoch 50  completed out of  100 Loss: 3727.766490906487\n",
            "Epoch 51  completed out of  100 Loss: 3954.9210019723473\n",
            "Epoch 52  completed out of  100 Loss: 3583.6757720783353\n",
            "Epoch 53  completed out of  100 Loss: 3200.3410043229233\n",
            "Epoch 54  completed out of  100 Loss: 4360.6712545752525\n",
            "Epoch 55  completed out of  100 Loss: 4226.53769159317\n",
            "Epoch 56  completed out of  100 Loss: 2920.553620547056\n",
            "Epoch 57  completed out of  100 Loss: 4174.132659558058\n",
            "Epoch 58  completed out of  100 Loss: 3532.6745641231537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 59  completed out of  100 Loss: 3951.1962649077177\n",
            "Epoch 60  completed out of  100 Loss: 2137.1451798677444\n",
            "Epoch 61  completed out of  100 Loss: 2670.750550687313\n",
            "Epoch 62  completed out of  100 Loss: 6789.20169929415\n",
            "Epoch 63  completed out of  100 Loss: 3720.6374916460827\n",
            "Epoch 64  completed out of  100 Loss: 2851.131561279297\n",
            "Epoch 65  completed out of  100 Loss: 3227.622255563736\n",
            "Epoch 66  completed out of  100 Loss: 4279.234448313713\n",
            "Epoch 67  completed out of  100 Loss: 2385.578045175395\n",
            "Epoch 68  completed out of  100 Loss: 3084.3963220119476\n",
            "Epoch 69  completed out of  100 Loss: 2864.400729558463\n",
            "Epoch 70  completed out of  100 Loss: 3918.8514746546743\n",
            "Epoch 71  completed out of  100 Loss: 2645.395414158702\n",
            "Epoch 72  completed out of  100 Loss: 2770.491116911173\n",
            "Epoch 73  completed out of  100 Loss: 3360.080692831427\n",
            "Epoch 74  completed out of  100 Loss: 2698.038199722767\n",
            "Epoch 75  completed out of  100 Loss: 2154.6806311011314\n",
            "Epoch 76  completed out of  100 Loss: 2258.8318009376526\n",
            "Epoch 77  completed out of  100 Loss: 2955.7575251981616\n",
            "Epoch 78  completed out of  100 Loss: 3241.6286563450194\n",
            "Epoch 79  completed out of  100 Loss: 2124.4864555597305\n",
            "Epoch 80  completed out of  100 Loss: 3489.4544007778168\n",
            "Epoch 81  completed out of  100 Loss: 3169.7353860119038\n",
            "Epoch 82  completed out of  100 Loss: 2141.876168881356\n",
            "Epoch 83  completed out of  100 Loss: 2708.431473135948\n",
            "Epoch 84  completed out of  100 Loss: 3282.7241232250817\n",
            "Epoch 85  completed out of  100 Loss: 2342.6953762983903\n",
            "Epoch 86  completed out of  100 Loss: 2370.2258887439966\n",
            "Epoch 87  completed out of  100 Loss: 1925.5543776154518\n",
            "Epoch 88  completed out of  100 Loss: 2280.56056971848\n",
            "Epoch 89  completed out of  100 Loss: 2388.845666408539\n",
            "Epoch 90  completed out of  100 Loss: 2835.3743284521042\n",
            "Epoch 91  completed out of  100 Loss: 2526.680446229857\n",
            "Epoch 92  completed out of  100 Loss: 2957.94068595767\n",
            "Epoch 93  completed out of  100 Loss: 1915.8570180753595\n",
            "Epoch 94  completed out of  100 Loss: 2129.214616037905\n",
            "Epoch 95  completed out of  100 Loss: 1844.2372323274612\n",
            "Epoch 96  completed out of  100 Loss: 2805.0240761339664\n",
            "Epoch 97  completed out of  100 Loss: 1478.4215990900993\n",
            "Epoch 98  completed out of  100 Loss: 2042.0295345751301\n",
            "Epoch 99  completed out of  100 Loss: 2963.9255934568064\n",
            "Accuracuy 0.9746\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}